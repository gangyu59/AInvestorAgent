from __future__ import annotations
from dataclasses import dataclass
from backend.factors.momentum import momentum_return, _last_close
from typing import Dict, List, Optional
from datetime import date
from sqlalchemy.orm import Session

from backend.factors.momentum import momentum_return
from backend.factors.sentiment import avg_sentiment_7d
from backend.storage import models

# åŸºçº¿æƒé‡ï¼ˆå¯åœ¨ .env æˆ–é…ç½®ä¸­è¦†ç›–ï¼‰
BASE_WEIGHTS = {"value": 0.25, "quality": 0.20, "momentum": 0.35, "sentiment": 0.20}

@dataclass
class FactorRow:
    symbol: str
    f_value: Optional[float] = None
    f_quality: Optional[float] = None
    f_momentum_raw: Optional[float] = None
    f_sentiment: Optional[float] = None
    f_momentum: Optional[float] = None


def _minmax_scale(arr: List[Optional[float]]) -> List[Optional[float]]:
    vals = [x for x in arr if x is not None]
    if not vals:
        return [None] * len(arr)

    lo, hi = min(vals), max(vals)

    # â­ ä¿®æ”¹è¿™é‡Œï¼šå•å€¼æ—¶ç›´æ¥è¿”å›åŸå€¼ï¼ˆä¸ç¼©æ”¾ï¼‰
    if len(vals) == 1:
        return arr  # å•å€¼ä¸ç¼©æ”¾ï¼Œä¿æŒåŸå€¼

    if hi - lo < 1e-12:  # å¤šä¸ªå€¼ä½†éƒ½ç›¸åŒ
        return [0.5 if x is not None else None for x in arr]

    return [None if x is None else (x - lo) / (hi - lo) for x in arr]


def compute_factors(db: Session, symbols: List[str], asof: date) -> List[FactorRow]:
    rows: List[FactorRow] = []
    for s in symbols:
        # åŠ¨é‡å’Œæƒ…ç»ª
        mom_r = momentum_return(db, s, asof, lookback_days=60)
        senti = avg_sentiment_7d(db, s, asof, days=30)

        # â­ æ·»åŠ è°ƒè¯•è¾“å‡º
        print(f"  {s} åŸå§‹åŠ¨é‡è¿”å›å€¼={mom_r}")

        # æ·»åŠ ä»·å€¼å’Œè´¨é‡å› å­è®¡ç®—
        f_value = _compute_value_factor(db, s, asof)
        f_quality = _compute_quality_factor(db, s, asof)

        rows.append(FactorRow(
            symbol=s,
            f_value=f_value,
            f_quality=f_quality,
            f_momentum_raw=mom_r,  # â­ ä¿å­˜åŸå§‹å€¼
            f_sentiment=senti
        ))

    # â­ è°ƒè¯•ï¼šæ˜¾ç¤ºç¼©æ”¾å‰åçš„åŠ¨é‡å€¼
    raw_momentums = [r.f_momentum_raw for r in rows]
    print(f"\nğŸ“Š ç¼©æ”¾å‰åŠ¨é‡åˆ—è¡¨: {raw_momentums}")

    scaled = _minmax_scale(raw_momentums)
    print(f"ğŸ“Š ç¼©æ”¾ååŠ¨é‡åˆ—è¡¨: {scaled}\n")

    for r, m in zip(rows, scaled):
        r.f_momentum = m
    return rows


def _compute_value_factor(db: Session, symbol: str, asof: date) -> float:
    """è®¡ç®—ä»·å€¼å› å­(åŸºäº PE/PB)"""
    from backend.storage.models import Fundamental

    fund = db.query(Fundamental).filter(
        Fundamental.symbol == symbol
    ).order_by(Fundamental.as_of.desc()).first()

    if not fund:
        print(f"  âš ï¸ {symbol}: æ•°æ®åº“ä¸­æ— åŸºæœ¬é¢æ•°æ®")
        return 0.5

    scores = []

    # PEå› å­(ä½PEé«˜åˆ†)
    if fund.pe and fund.pe > 0:
        # å¤„ç†æç«¯å€¼ï¼šTSLAçš„PE=243å¤ªé«˜
        if fund.pe > 100:
            pe_score = 0.0  # ä¼°å€¼è¿‡é«˜ï¼Œç»™æœ€ä½åˆ†
        elif fund.pe < 10:
            pe_score = 1.0  # ä¼°å€¼å¾ˆä½ï¼Œç»™æœ€é«˜åˆ†
        else:
            # æ­£å¸¸èŒƒå›´ï¼š10-50
            pe_score = max(0, min(1, (50 - fund.pe) / 40))
        scores.append(pe_score)
        print(f"  {symbol} PE={fund.pe:.2f} â†’ PEåˆ†æ•°={pe_score:.3f}")
    else:
        print(f"  âš ï¸ {symbol}: PEæ•°æ®æ— æ•ˆ({fund.pe})")

    # PBå› å­(ä½PBé«˜åˆ†)
    if fund.pb and fund.pb > 0:
        # AAPLçš„PB=57.97å¤ªé«˜ï¼Œè¯´æ˜æ˜¯æˆé•¿è‚¡
        if fund.pb > 20:
            pb_score = 0.0
        elif fund.pb < 2:
            pb_score = 1.0
        else:
            # æ­£å¸¸èŒƒå›´ï¼š2-10
            pb_score = max(0, min(1, (10 - fund.pb) / 8))
        scores.append(pb_score)
        print(f"  {symbol} PB={fund.pb:.2f} â†’ PBåˆ†æ•°={pb_score:.3f}")
    else:
        print(f"  âš ï¸ {symbol}: PBæ•°æ®æ— æ•ˆ({fund.pb})")

    if not scores:
        print(f"  âš ï¸ {symbol}: æ— æœ‰æ•ˆPE/PBæ•°æ®ï¼Œè¿”å›ä¸­æ€§0.5")
        return 0.5

    final = sum(scores) / len(scores)
    print(f"  âœ… {symbol} ä»·å€¼å› å­={final:.3f}")
    return final


def _compute_quality_factor(db: Session, symbol: str, asof: date) -> float:
    """è®¡ç®—è´¨é‡å› å­(åŸºäº ROE/å‡€åˆ©ç‡)"""
    from backend.storage.models import Fundamental

    fund = db.query(Fundamental).filter(
        Fundamental.symbol == symbol
    ).order_by(Fundamental.as_of.desc()).first()

    if not fund:
        print(f"  âš ï¸ {symbol}: æ•°æ®åº“ä¸­æ— åŸºæœ¬é¢æ•°æ®")
        return 0.5

    scores = []

    # ROEå› å­ï¼ˆæ³¨æ„ï¼šæ•°æ®åº“é‡Œçš„ROEå¯èƒ½æ˜¯å°æ•°æˆ–ç™¾åˆ†æ¯”ï¼‰
    if fund.roe is not None and fund.roe != 0:
        # åˆ¤æ–­æ˜¯å°æ•°æ ¼å¼(0.xx)è¿˜æ˜¯ç™¾åˆ†æ¯”æ ¼å¼(xx.xx)
        roe_pct = fund.roe if fund.roe > 1 else fund.roe * 100

        if roe_pct < 0:
            roe_score = 0.0  # è´ŸROEæœ€ä½åˆ†
        elif roe_pct > 30:
            roe_score = 1.0  # è¶…é«˜ROEæœ€é«˜åˆ†
        else:
            # æ­£å¸¸èŒƒå›´ï¼š0-30%
            roe_score = max(0, min(1, roe_pct / 30))
        scores.append(roe_score)
        print(f"  {symbol} ROE={roe_pct:.2f}% â†’ ROEåˆ†æ•°={roe_score:.3f}")
    else:
        print(f"  âš ï¸ {symbol}: ROEæ•°æ®æ— æ•ˆ({fund.roe})")

    # å‡€åˆ©ç‡å› å­
    if fund.net_margin is not None and fund.net_margin != 0:
        margin_pct = fund.net_margin if fund.net_margin > 1 else fund.net_margin * 100

        if margin_pct < 0:
            margin_score = 0.0
        elif margin_pct > 25:
            margin_score = 1.0
        else:
            # æ­£å¸¸èŒƒå›´ï¼š0-25%
            margin_score = max(0, min(1, margin_pct / 25))
        scores.append(margin_score)
        print(f"  {symbol} å‡€åˆ©ç‡={margin_pct:.2f}% â†’ åˆ©æ¶¦ç‡åˆ†æ•°={margin_score:.3f}")
    else:
        print(f"  âš ï¸ {symbol}: å‡€åˆ©ç‡æ•°æ®æ— æ•ˆ({fund.net_margin})")

    if not scores:
        print(f"  âš ï¸ {symbol}: æ— æœ‰æ•ˆROE/å‡€åˆ©ç‡æ•°æ®ï¼Œè¿”å›ä¸­æ€§0.5")
        return 0.5

    final = sum(scores) / len(scores)
    print(f"  âœ… {symbol} è´¨é‡å› å­={final:.3f}")
    return final


def aggregate_score(row: FactorRow, weights: Dict[str, float]=BASE_WEIGHTS) -> float:
    parts = []
    total_w = 0.0
    for k, w in weights.items():
        v = {"value": row.f_value,
             "quality": row.f_quality,
             "momentum": getattr(row, "f_momentum", None),
             "sentiment": row.f_sentiment}[k]
        if v is None:
            continue
        parts.append(w * v)
        total_w += w
    if total_w <= 0:
        return 50.0  # å®Œå…¨ç¼ºå¤±æ—¶ç»™ä¸­æ€§åˆ†
    return 100.0 * sum(parts) / total_w

def upsert_scores(db: Session, asof: date, rows: List[FactorRow], version_tag="v0.1"):
    for r in rows:
        score = aggregate_score(r)
        obj = (db.query(models.ScoreDaily)
                 .filter(models.ScoreDaily.as_of == asof,
                         models.ScoreDaily.symbol == r.symbol)
                 .one_or_none())
        data = dict(as_of=asof, symbol=r.symbol,
                    f_value=r.f_value, f_quality=r.f_quality,
                    f_momentum=getattr(r, "f_momentum", None),
                    f_sentiment=r.f_sentiment, score=score,
                    version_tag=version_tag)
        if obj:
            for k, v in data.items(): setattr(obj, k, v)
        else:
            db.add(models.ScoreDaily(**data))
    db.commit()

# === Portfolio builder (è¿½åŠ ) ===
@dataclass
class Pick:
    symbol: str
    score: float
    f_value: Optional[float]
    f_quality: Optional[float]
    f_momentum: Optional[float]
    f_sentiment: Optional[float]
    weight: float

def _clip_and_renorm(weights: List[float], min_w: float, max_w: float) -> List[float]:
    # å…ˆè£å‰ªï¼Œå†å¯¹æœªè¾¾æ ‡éƒ¨åˆ†æŒ‰æ¯”ä¾‹è¡¥é½ï¼Œæœ€å¤šè¿­ä»£3æ¬¡é¿å…æ•°å€¼è¯¯å·®
    import math
    w = [min(max(x, 0.0), 1.0) for x in weights]
    for _ in range(3):
        w = [min(max(x, min_w), max_w) for x in w]
        s = sum(w)
        if s <= 0:
            w = [1.0/len(w)] * len(w); break
        w = [x/s for x in w]
        # è‹¥å†è£å‰ªä¸ä¼šå˜åŒ–å°±é€€å‡º
        w2 = [min(max(x, min_w), max_w) for x in w]
        if all(math.isclose(a, b, rel_tol=1e-9, abs_tol=1e-12) for a, b in zip(w, w2)):
            break
        w = w2
    # å†åšä¸€æ¬¡ç²¾ç¡®å½’ä¸€
    s = sum(w)
    return [x/s for x in w] if s > 0 else [1.0/len(w)]*len(w)

def build_portfolio(
    db: Session,
    symbols: List[str],
    asof: date,
    top_n: int = 5,
    scheme: str = "proportional",  # "equal" or "proportional"
    alpha: float = 1.0,             # å¯¹åˆ†æ•°åšæŒ‡æ•°ï¼Œalpha>1æ›´é›†ä¸­
    min_w: float = 0.0,
    max_w: float = 0.4,
) -> Dict:
    """
    ä»æ‰“åˆ†ä¸­é€‰å‡º Top-Nï¼Œå¹¶æ ¹æ® scheme ç”Ÿæˆæƒé‡ï¼ˆè£å‰ªåˆ° [min_w,max_w] åå½’ä¸€ï¼‰ã€‚
    è¿”å› dict: {as_of, version_tag, items:[{symbol,score,f_*,weight}], meta:{...}}
    """
    rows = compute_factors(db, symbols, asof)
    # è®¡ç®—åˆ†æ•°ï¼ˆä½¿ç”¨ä½ ç°æœ‰ aggregate_scoreï¼‰
    scored = []
    for r in rows:
        s = aggregate_score(r)  # 0..100
        scored.append((s, r))
    # å– Top-N
    scored.sort(key=lambda t: t[0], reverse=True)
    top = scored[:max(1, min(top_n, len(scored)))]
    # æƒé‡
    if scheme == "equal":
        raw = [1.0/len(top)] * len(top)
    else:
        # proportional to score^alpha
        xs = [max(t[0], 1e-6) ** max(alpha, 0.0) for t in top]
        s = sum(xs)
        raw = [x/s for x in xs] if s > 0 else [1.0/len(top)] * len(top)
    w = _clip_and_renorm(raw, min_w, max_w)

    items: List[Pick] = []
    for (score, r), wi in zip(top, w):
        items.append(Pick(
            symbol=r.symbol, score=score,
            f_value=r.f_value, f_quality=r.f_quality,
            f_momentum=getattr(r, "f_momentum", None),
            f_sentiment=r.f_sentiment,
            weight=round(wi, 6),
        ))
    # é¡ºæ‰‹æŠŠ scores å†™åº“ï¼ˆä½ å·²æœ‰ upsert_scoresï¼‰
    upsert_scores(db, asof, [t[1] for t in top], version_tag="v0.1")
    return {
        "as_of": asof.isoformat(),
        "version_tag": "v0.1",
        "items": [i.__dict__ for i in items],
        "meta": {"scheme": scheme, "alpha": alpha, "min_w": min_w, "max_w": max_w}
    }


# === å› å­æœ‰æ•ˆæ€§éªŒè¯ (è¿½åŠ åˆ°ç°æœ‰ scorer.py) ===
from scipy import stats
import numpy as np


def validate_factor_effectiveness(db: Session, symbols: List[str],
                                  lookback_months: int = 12) -> Dict[str, Dict]:
    """
    éªŒè¯å› å­æœ‰æ•ˆæ€§ï¼šè®¡ç®— IC (Information Coefficient)
    IC = å› å­å€¼ä¸æœªæ¥æ”¶ç›Šçš„ç›¸å…³æ€§
    """
    from datetime import timedelta
    import pandas as pd

    results = {
        'momentum': {'ic_series': [], 'ic_mean': 0.0, 'ic_std': 0.0, 'ic_ir': 0.0},
        'sentiment': {'ic_series': [], 'ic_mean': 0.0, 'ic_std': 0.0, 'ic_ir': 0.0},
        'overall_score': {'ic_series': [], 'ic_mean': 0.0, 'ic_std': 0.0, 'ic_ir': 0.0}
    }

    try:
        end_date = date.today()
        start_date = end_date - timedelta(days=lookback_months * 30)

        # æŒ‰æœˆè®¡ç®—IC
        current_date = start_date
        while current_date < end_date:
            next_month = current_date + timedelta(days=30)

            # è·å–å½“æœˆå› å­å€¼
            factor_data = []
            future_returns = []

            for symbol in symbols:
                # å½“æœˆå› å­
                mom_factor = momentum_return(db, symbol, current_date, 60)
                sent_factor = avg_sentiment_7d(db, symbol, current_date, 7)

                # æœªæ¥1æœˆæ”¶ç›Š
                current_price = _last_close(db, symbol, current_date)
                future_price = _last_close(db, symbol, next_month)

                if all(x is not None for x in [mom_factor, sent_factor, current_price, future_price]):
                    future_ret = (future_price / current_price) - 1.0

                    # è®¡ç®—ç»¼åˆåˆ†æ•°
                    row = FactorRow(symbol, None, None, mom_factor, sent_factor)
                    scaled_mom = _minmax_scale([mom_factor])[0] or 0.5
                    row.f_momentum = scaled_mom
                    overall_score = aggregate_score(row)

                    factor_data.append({
                        'momentum': scaled_mom,
                        'sentiment': sent_factor,
                        'overall_score': overall_score / 100.0  # å½’ä¸€åŒ–åˆ°0-1
                    })
                    future_returns.append(future_ret)

            # è®¡ç®—å½“æœˆIC
            if len(factor_data) >= 5:  # è‡³å°‘5åªè‚¡ç¥¨
                for factor_name in ['momentum', 'sentiment', 'overall_score']:
                    factor_values = [d[factor_name] for d in factor_data]
                    ic, p_value = stats.pearsonr(factor_values, future_returns)
                    if not np.isnan(ic):
                        results[factor_name]['ic_series'].append(ic)

            current_date = next_month

        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        for factor_name in results:
            ic_series = results[factor_name]['ic_series']
            if ic_series:
                results[factor_name]['ic_mean'] = float(np.mean(ic_series))
                results[factor_name]['ic_std'] = float(np.std(ic_series))
                results[factor_name]['ic_ir'] = (
                    results[factor_name]['ic_mean'] / results[factor_name]['ic_std']
                    if results[factor_name]['ic_std'] > 0 else 0.0
                )
                # æ­£ICå æ¯”
                positive_rate = sum(1 for ic in ic_series if ic > 0) / len(ic_series)
                results[factor_name]['positive_rate'] = positive_rate

    except Exception as e:
        print(f"å› å­æœ‰æ•ˆæ€§éªŒè¯å¤±è´¥: {e}")

    return results


def get_portfolio_risk_metrics(db: Session, weights: List[Dict[str, Any]],
                               asof: date) -> Dict[str, float]:
    """
    è®¡ç®—ç»„åˆé£é™©æŒ‡æ ‡
    """
    from backend.factors.risk import calculate_risk_metrics, get_price_series

    portfolio_metrics = {}

    try:
        total_weight = sum(w.get('weight', 0) for w in weights)
        if total_weight <= 0:
            return portfolio_metrics

        # è·å–å„è‚¡ç¥¨çš„å†å²æ”¶ç›Šç‡
        all_returns = []
        valid_weights = []

        for w in weights:
            symbol = w.get('symbol')
            weight = w.get('weight', 0) / total_weight  # å½’ä¸€åŒ–æƒé‡

            if symbol and weight > 0:
                df = get_price_series(db, symbol, asof, 252)
                if len(df) >= 30:
                    prices = df['close'].tolist()
                    returns = [(prices[i] - prices[i - 1]) / prices[i - 1]
                               for i in range(1, len(prices))]

                    all_returns.append(np.array(returns) * weight)
                    valid_weights.append(weight)

        if all_returns:
            # è®¡ç®—ç»„åˆæ”¶ç›Šç‡åºåˆ—
            min_length = min(len(r) for r in all_returns)
            portfolio_returns = np.sum([r[:min_length] for r in all_returns], axis=0)

            # ç»„åˆé£é™©æŒ‡æ ‡
            portfolio_metrics['portfolio_volatility'] = float(np.std(portfolio_returns) * np.sqrt(252))
            portfolio_metrics['portfolio_var_95'] = float(np.percentile(portfolio_returns, 5))
            portfolio_metrics['portfolio_var_99'] = float(np.percentile(portfolio_returns, 1))

            # æœ€å¤§å›æ’¤ï¼ˆç»„åˆå±‚é¢ï¼‰
            cumulative = np.cumprod(1 + portfolio_returns)
            peak = np.maximum.accumulate(cumulative)
            drawdown = (cumulative - peak) / peak
            portfolio_metrics['portfolio_max_drawdown'] = float(np.min(drawdown))

            # å¤æ™®æ¯”ç‡
            excess_return = np.mean(portfolio_returns) * 252 - 0.02  # å‡è®¾æ— é£é™©åˆ©ç‡2%
            portfolio_metrics['portfolio_sharpe'] = (
                excess_return / portfolio_metrics['portfolio_volatility']
                if portfolio_metrics['portfolio_volatility'] > 0 else 0.0
            )

            # é›†ä¸­åº¦é£é™©
            portfolio_metrics['concentration_risk'] = float(np.sum(np.array(valid_weights) ** 2))

    except Exception as e:
        print(f"ç»„åˆé£é™©æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")

    return portfolio_metrics