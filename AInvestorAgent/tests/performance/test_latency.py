"""
æ€§èƒ½å’Œå»¶è¿Ÿæµ‹è¯•
æµ‹è¯•ç³»ç»Ÿå“åº”æ—¶é—´å’Œååé‡
"""
import pytest
import requests
import time
import statistics
from typing import List


class TestEndpointLatency:
    """ç«¯ç‚¹å»¶è¿Ÿæµ‹è¯•"""

    def test_01_health_endpoint_latency(self, base_url):
        """æµ‹è¯•: å¥åº·æ£€æŸ¥ç«¯ç‚¹å»¶è¿Ÿ"""
        print("\n" + "="*60)
        print("æµ‹è¯•: å¥åº·æ£€æŸ¥ç«¯ç‚¹å»¶è¿Ÿ")
        print("="*60)

        latencies = []
        iterations = 10

        for i in range(iterations):
            start = time.time()
            response = requests.get(f"{base_url}/health", timeout=5)
            latency = (time.time() - start) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’

            if response.status_code == 200:
                latencies.append(latency)

        if latencies:
            avg_latency = statistics.mean(latencies)
            p95_latency = statistics.quantiles(latencies, n=20)[18]  # 95th percentile

            print(f"   ğŸ“Š å¹³å‡å»¶è¿Ÿ: {avg_latency:.2f}ms")
            print(f"   ğŸ“Š P95å»¶è¿Ÿ: {p95_latency:.2f}ms")
            print(f"   ğŸ“Š æœ€å°: {min(latencies):.2f}ms")
            print(f"   ğŸ“Š æœ€å¤§: {max(latencies):.2f}ms")

            # ç›®æ ‡: å¹³å‡å»¶è¿Ÿ <100ms
            if avg_latency < 100:
                print(f"   âœ… å»¶è¿Ÿä¼˜ç§€")
            elif avg_latency < 500:
                print(f"   âœ… å»¶è¿Ÿè‰¯å¥½")
            else:
                print(f"   âš ï¸  å»¶è¿Ÿè¾ƒé«˜")

    def test_02_price_api_latency(self, base_url):
        """æµ‹è¯•: ä»·æ ¼APIå»¶è¿Ÿ"""
        print("\n" + "="*60)
        print("æµ‹è¯•: ä»·æ ¼APIå»¶è¿Ÿ")
        print("="*60)

        latencies = []
        symbol = "AAPL"

        for i in range(5):
            start = time.time()
            response = requests.get(
                f"{base_url}/api/prices/{symbol}?range=1M",
                timeout=30
            )
            latency = (time.time() - start) * 1000

            if response.status_code == 200:
                latencies.append(latency)

        if latencies:
            avg_latency = statistics.mean(latencies)

            print(f"   ğŸ“Š å¹³å‡å»¶è¿Ÿ: {avg_latency:.2f}ms")

            # ç›®æ ‡: <2ç§’
            if avg_latency < 2000:
                print(f"   âœ… å»¶è¿Ÿè¾¾æ ‡ (<2s)")
            else:
                print(f"   âš ï¸  å»¶è¿Ÿè¶…æ ‡: {avg_latency/1000:.2f}s")

    def test_03_decide_endpoint_latency(self, base_url):
        """æµ‹è¯•: å†³ç­–ç«¯ç‚¹å»¶è¿Ÿ"""
        print("\n" + "="*60)
        print("æµ‹è¯•: å†³ç­–ç«¯ç‚¹å»¶è¿Ÿ")
        print("="*60)

        latencies = []

        for i in range(3):
            print(f"\n   ç¬¬{i+1}æ¬¡æµ‹è¯•...")
            start = time.time()

            response = requests.post(
                f"{base_url}/api/orchestrator/decide",
                json={"topk": 10, "mock": False},
                timeout=120
            )

            latency = (time.time() - start) * 1000

            if response.status_code == 200:
                latencies.append(latency)
                print(f"      å»¶è¿Ÿ: {latency/1000:.2f}s")

        if latencies:
            avg_latency = statistics.mean(latencies)

            print(f"\n   ğŸ“Š å¹³å‡å»¶è¿Ÿ: {avg_latency/1000:.2f}ç§’")

            # ç›®æ ‡: <60ç§’
            if avg_latency < 60000:
                print(f"   âœ… å»¶è¿Ÿè¾¾æ ‡ (<60s)")
            else:
                print(f"   âš ï¸  å»¶è¿Ÿè¶…æ ‡")


class TestThroughput:
    """ååé‡æµ‹è¯•"""

    def test_01_concurrent_health_checks(self, base_url):
        """æµ‹è¯•: å¹¶å‘å¥åº·æ£€æŸ¥"""
        print("\n" + "="*60)
        print("æµ‹è¯•: å¹¶å‘å¥åº·æ£€æŸ¥")
        print("="*60)

        import concurrent.futures

        def single_request():
            try:
                response = requests.get(f"{base_url}/health", timeout=5)
                return response.status_code == 200
            except:
                return False

        concurrent_level = 10
        print(f"\n   å¹¶å‘è¯·æ±‚æ•°: {concurrent_level}")

        start = time.time()
        with concurrent.futures.ThreadPoolExecutor(max_workers=concurrent_level) as executor:
            futures = [executor.submit(single_request) for _ in range(concurrent_level)]
            results = [f.result() for f in concurrent.futures.as_completed(futures)]

        elapsed = time.time() - start

        success_count = sum(results)
        throughput = success_count / elapsed

        print(f"   ğŸ“Š æˆåŠŸ: {success_count}/{concurrent_level}")
        print(f"   ğŸ“Š æ€»è€—æ—¶: {elapsed:.2f}ç§’")
        print(f"   ğŸ“Š ååé‡: {throughput:.2f} req/s")

        assert success_count >= concurrent_level * 0.8, "æˆåŠŸç‡<80%"

    def test_02_sequential_api_calls(self, base_url):
        """æµ‹è¯•: é¡ºåºAPIè°ƒç”¨"""
        print("\n" + "="*60)
        print("æµ‹è¯•: é¡ºåºAPIè°ƒç”¨")
        print("="*60)

        symbols = ["AAPL", "MSFT", "GOOGL", "NVDA", "TSLA"]

        start = time.time()
        success_count = 0

        for symbol in symbols:
            try:
                response = requests.get(
                    f"{base_url}/api/prices/{symbol}?range=1M",
                    timeout=30
                )
                if response.status_code == 200:
                    success_count += 1
            except:
                pass

        elapsed = time.time() - start

        print(f"   ğŸ“Š æˆåŠŸ: {success_count}/{len(symbols)}")
        print(f"   ğŸ“Š æ€»è€—æ—¶: {elapsed:.2f}ç§’")
        print(f"   ğŸ“Š å¹³å‡æ¯æ¬¡: {elapsed/len(symbols):.2f}ç§’")

        assert success_count >= len(symbols) * 0.8


class TestCachingPerformance:
    """ç¼“å­˜æ€§èƒ½æµ‹è¯•"""

    def test_01_repeated_price_requests(self, base_url):
        """æµ‹è¯•: é‡å¤ä»·æ ¼è¯·æ±‚ï¼ˆæµ‹è¯•ç¼“å­˜ï¼‰"""
        print("\n" + "="*60)
        print("æµ‹è¯•: é‡å¤ä»·æ ¼è¯·æ±‚ï¼ˆç¼“å­˜æ•ˆæœï¼‰")
        print("="*60)

        symbol = "AAPL"
        url = f"{base_url}/api/prices/{symbol}?range=1M"

        # ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼ˆå†·å¯åŠ¨ï¼‰
        start = time.time()
        response1 = requests.get(url, timeout=30)
        first_latency = (time.time() - start) * 1000

        # ç¬¬äºŒæ¬¡è¯·æ±‚ï¼ˆå¯èƒ½å‘½ä¸­ç¼“å­˜ï¼‰
        start = time.time()
        response2 = requests.get(url, timeout=30)
        second_latency = (time.time() - start) * 1000

        print(f"   ğŸ“Š ç¬¬ä¸€æ¬¡è¯·æ±‚: {first_latency:.2f}ms")
        print(f"   ğŸ“Š ç¬¬äºŒæ¬¡è¯·æ±‚: {second_latency:.2f}ms")

        if second_latency < first_latency * 0.8:
            print(f"   âœ… ç¼“å­˜ç”Ÿæ•ˆï¼ˆæé€Ÿ{((first_latency-second_latency)/first_latency)*100:.1f}%ï¼‰")
        else:
            print(f"   â„¹ï¸  ç¼“å­˜å¯èƒ½æœªå®ç°æˆ–æœªç”Ÿæ•ˆ")


class TestLoadHandling:
    """è´Ÿè½½å¤„ç†æµ‹è¯•"""

    def test_01_sustained_load(self, base_url):
        """æµ‹è¯•: æŒç»­è´Ÿè½½"""
        print("\n" + "="*60)
        print("æµ‹è¯•: æŒç»­è´Ÿè½½ï¼ˆ30ç§’ï¼‰")
        print("="*60)

        duration = 30  # ç§’
        start_time = time.time()
        request_count = 0
        success_count = 0

        print(f"\n   å¼€å§‹æŒç»­è¯·æ±‚...")

        while time.time() - start_time < duration:
            try:
                response = requests.get(f"{base_url}/health", timeout=5)
                request_count += 1
                if response.status_code == 200:
                    success_count += 1
            except:
                request_count += 1

            time.sleep(0.1)  # 100msé—´éš”

        elapsed = time.time() - start_time
        success_rate = success_count / request_count if request_count > 0 else 0
        avg_rps = request_count / elapsed

        print(f"\n   ğŸ“Š æ€»è¯·æ±‚: {request_count}")
        print(f"   ğŸ“Š æˆåŠŸ: {success_count}")
        print(f"   ğŸ“Š æˆåŠŸç‡: {success_rate:.1%}")
        print(f"   ğŸ“Š å¹³å‡RPS: {avg_rps:.2f}")

        assert success_rate >= 0.95, f"æˆåŠŸç‡è¿‡ä½: {success_rate:.1%}"


if __name__ == "__main__":
    pytest.main([__file__, "-v", "--tb=short"])